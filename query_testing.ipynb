{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pe_modules\n",
    "import users\n",
    "import dataloaders\n",
    "import llms\n",
    "import jinja2\n",
    "import argparse\n",
    "import yaml\n",
    "\n",
    "config_path = \"./configs/david_base_config.yaml\"\n",
    "\n",
    "config = yaml.safe_load(open(config_path))\n",
    "\n",
    "# Load data\n",
    "dataloader_class = dataloaders.DATALOADER_CLASSES[config['data']['data_loader_name']]\n",
    "dataloader = dataloader_class(config) # Could force to be DataLoader class here?\n",
    "items = dataloader.get_data()\n",
    "\n",
    "# Load other helpers\n",
    "jinja_env = jinja2.Environment(loader=jinja2.FileSystemLoader(searchpath='./templates'))\n",
    "llm_module = llms.LLM_CLASSES[config['llm']['llm_name']]\n",
    "llm = llm_module(config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "You must determine whether or not a user will like an item based on a description of the item and \n",
      "a sequence of queries posed to the user and the user's responses. Your answer can only be true or false.\n",
      "\n",
      "''''\n",
      "Example 1:\n",
      "A user has the following past interactions:\n",
      "####\n",
      "Query: Do you care about fuel mileage? \n",
      "Response: No, I don't really care about that.\n",
      "####\n",
      "####\n",
      "Query: Do you want a sports car? \n",
      "Response: Yes\n",
      "####\n",
      "An item has the following descriptions: \n",
      "####\n",
      "Description: This is a grey four-door sedan that focuses on fuel efficiency and low budget.\n",
      "####\n",
      "Is the following statement true or false: This user will like this item. Answer only with True or False.\n",
      "Your response: False\n",
      "''''\n",
      "\n",
      "''''\n",
      "Example 2:\n",
      "A user has the following past interactions:\n",
      "####\n",
      "Query: Do you want an electric guitar or an acoustic guitar?\n",
      "Response: Electric\n",
      "####\n",
      "####\n",
      "Query: What type of pickups do you want?\n",
      "Response: Two humbucker pickups\n",
      "####\n",
      "####\n",
      "Query: Is there a brand that you prefer?\n",
      "Response: I like Gibson, but Epiphone is fine too.\n",
      "####\n",
      "An item has the following descriptions: \n",
      "####\n",
      "Description: Gibson SG335 electric guitar with two humbucker pickups and a semi-hollow body shape. Colour: Crimson\n",
      "####\n",
      "Is the following statement true or false: This user will like this item. Answer only with True or False.\n",
      "Your response: True\n",
      "''''\n",
      "\n",
      "''''\n",
      "Here is the real query:\n",
      "A customer has the following past interactions:\n",
      "\n",
      "####\n",
      "Query: Are you looking for a football?\n",
      "Response: Yes\n",
      "####\n",
      "\n",
      "An item has the following reviews: \n",
      "\n",
      "Is the following statement true or false: This user will like this item. Answer only with True or False.\n",
      "Your response: \n"
     ]
    }
   ],
   "source": [
    "i = 3\n",
    "\n",
    "item_desc = items[i]['description'] #NOTE: Currently item_idx is a list to support returning multiple\n",
    "interactions = [{\"query\": \"Are you looking for a football?\", \"response\": \"Yes\"}]\n",
    "\n",
    "template_file = config['llm']['like_probs_template'] \n",
    "query_template = jinja_env.get_template(template_file)\n",
    "context = {\n",
    "            \"item_desc\": item_desc,\n",
    "            \"interactions\": interactions\n",
    "}\n",
    "query = query_template.render(context)\n",
    "print(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"finish_reason\": \"stop\",\n",
      "      \"index\": 0,\n",
      "      \"logprobs\": {\n",
      "        \"text_offset\": [\n",
      "          1626\n",
      "        ],\n",
      "        \"token_logprobs\": [\n",
      "          -0.6548007\n",
      "        ],\n",
      "        \"tokens\": [\n",
      "          \"True\"\n",
      "        ],\n",
      "        \"top_logprobs\": [\n",
      "          {\n",
      "            \"True\": -0.6548007\n",
      "          }\n",
      "        ]\n",
      "      },\n",
      "      \"text\": \"True\"\n",
      "    }\n",
      "  ],\n",
      "  \"created\": 1701962076,\n",
      "  \"id\": \"cmpl-8TANAvcAEv4vnJe81heAgXqPuq74w\",\n",
      "  \"model\": \"gpt-3.5-turbo-instruct\",\n",
      "  \"object\": \"text_completion\",\n",
      "  \"usage\": {\n",
      "    \"completion_tokens\": 1,\n",
      "    \"prompt_tokens\": 364,\n",
      "    \"total_tokens\": 365\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "response = llm.make_request(query, temperature=config['llm']['temperature'], logprobs=1)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"True\": -0.6548007\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(response['choices'][0][\"logprobs\"][\"token_logprobs\"])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-pe",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
